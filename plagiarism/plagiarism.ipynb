{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "sys.path.append('/screamlab/home/eri24816/improved-diffusion')\n",
    "from os import path \n",
    "from utils.pianoroll import PianoRoll, PianoRollDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from metrics import iou, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset 32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2570"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keys\n",
    "data_dir = '/screamlab/home/eri24816/pianoroll_dataset/data/dataset_1/pianoroll/'\n",
    "songs = PianoRollDataset(data_dir,32,32,metadata_file='/screamlab/home/eri24816/pianoroll_dataset/data/dataset_1/metadata.csv')\n",
    "len(songs.pianorolls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def get_sim_map(q,k,sim_function):\n",
    "    m = []\n",
    "    for k_bar in k.split(32):\n",
    "        m.append(sim_function(q,k_bar))\n",
    "    return m\n",
    "\n",
    "def get_sim_maps(q,ks,sim_function = iou):\n",
    "    all_sim_maps : List[List] = [] # [key_song, query_pos, key_pos]\n",
    "    for k in tqdm(ks):\n",
    "        sim_maps : List[List] = [] # [query_pos, key_pos]\n",
    "        k = k.to_tensor()/128\n",
    "        for q_bar in q.split(32):\n",
    "            sim_maps.append(get_sim_map(q_bar,k,sim_function))\n",
    "        all_sim_maps.append(sim_maps)\n",
    "    return all_sim_maps\n",
    "\n",
    "def rank_similiar_parts(all_sim_maps, q_start=0, q_end=None):\n",
    "    # rank similarity maps\n",
    "    scores = []\n",
    "    for i_key,sim_maps in enumerate(all_sim_maps):\n",
    "        sim_maps = sim_maps[q_start:q_end]\n",
    "        q_len = len(sim_maps)\n",
    "        k_len = len(sim_maps[0])\n",
    "        for q_pos_on_k in range(k_len - q_len): # move query window over key\n",
    "            score = 0\n",
    "            for q_pos in range(q_len):\n",
    "                score += sim_maps[q_pos][q_pos_on_k+q_pos] # sum similarity of query bars\n",
    "\n",
    "            scores.append((i_key,q_pos_on_k,score.item()/q_len))\n",
    "    scores = sorted(scores,key=lambda x: x[2],reverse=True)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(q_file,ks,sim_function = iou):\n",
    "    global all_sim_maps\n",
    "    # load query\n",
    "    q = PianoRoll.from_midi(q_file).to_tensor(0,16*32,True)/128\n",
    "\n",
    "    # get bar to bar similarity maps. [key_song, query_pos, key_pos]\n",
    "    all_sim_maps = get_sim_maps(q,ks,sim_function)\n",
    "\n",
    "    # prepare save path\n",
    "    from os import path\n",
    "    import json\n",
    "    q_id = path.basename(q_file).replace('.mid','')\n",
    "    q_dir = path.dirname(q_file)\n",
    "    save_dir = path.join(q_dir,'similar',q_id)\n",
    "    os.makedirs(save_dir,exist_ok=True)\n",
    "\n",
    "    # prepare metadata\n",
    "    metadata_path = path.join(save_dir,'metadata.json')\n",
    "\n",
    "    files_metadata = {}\n",
    "\n",
    "    for q_start in range(0,16,4): # move query window over query (4 bars at a time)\n",
    "        q_end = q_start + 4\n",
    "\n",
    "        # rank similar keys\n",
    "        scores = rank_similiar_parts(all_sim_maps, q_start=q_start, q_end=q_end)\n",
    "\n",
    "        # save query\n",
    "        q_path = path.join(save_dir,f'{q_start}_query.mid')\n",
    "        PianoRoll.from_tensor(q*128).slice(q_start*32,q_end*32).to_midi(q_path)\n",
    "        files_metadata[path.basename(q_path)]={\n",
    "            'title':f'Query {q_id}',\n",
    "            'start':q_start,\n",
    "            'end':q_end,\n",
    "            'score':None\n",
    "        }\n",
    "\n",
    "        for rank,(i_key, q_pos_on_k, score) in enumerate(scores[:10]):\n",
    "            #print(i_key, q_pos_on_k, score,ks[i_key].metadata.name)\n",
    "            k = ks[i_key]\n",
    "            k_path = path.join(save_dir,f'{q_start}_{rank}.mid')\n",
    "            k.slice(q_pos_on_k*32,(q_pos_on_k+q_end-q_start)*32).to_midi(k_path)\n",
    "\n",
    "            files_metadata[path.basename(k_path)]={\n",
    "                'title':k.metadata.name,\n",
    "                'start':q_pos_on_k,\n",
    "                'end':q_pos_on_k + q_end - q_start,\n",
    "                'score':score\n",
    "            }\n",
    "    \n",
    "    # save metadata\n",
    "    metadata = {'files':files_metadata}\n",
    "    with open(metadata_path,'w') as f:\n",
    "        json.dump(metadata,f)\n",
    "    \n",
    "    # update global metadata\n",
    "    global_metadata_path = path.join(q_dir,'similar','metadata.json')\n",
    "    if not path.exists(global_metadata_path):\n",
    "        global_metadata = {'queries':[]}\n",
    "    else:\n",
    "        with open(global_metadata_path) as f:\n",
    "            global_metadata = json.load(f)\n",
    "    global_metadata['queries'].append(q_id)\n",
    "    with open(global_metadata_path,'w') as f:\n",
    "        json.dump(global_metadata,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2570/2570 [01:01<00:00, 41.78it/s]\n",
      "100%|██████████| 2570/2570 [01:01<00:00, 41.76it/s]\n",
      "100%|██████████| 2570/2570 [00:57<00:00, 44.66it/s]\n",
      "100%|██████████| 2570/2570 [00:57<00:00, 44.86it/s]\n",
      "100%|██████████| 2570/2570 [00:58<00:00, 44.03it/s]\n",
      "100%|██████████| 2570/2570 [00:57<00:00, 44.36it/s]\n",
      "100%|██████████| 2570/2570 [00:56<00:00, 45.80it/s]\n",
      "100%|██████████| 2570/2570 [01:01<00:00, 41.92it/s]\n",
      "100%|██████████| 2570/2570 [00:56<00:00, 45.18it/s]\n",
      "100%|██████████| 2570/2570 [00:57<00:00, 44.78it/s]\n",
      "100%|██████████| 2570/2570 [00:59<00:00, 43.21it/s]\n",
      "100%|██████████| 2570/2570 [00:59<00:00, 43.55it/s]\n",
      "100%|██████████| 2570/2570 [00:59<00:00, 43.03it/s]\n",
      "100%|██████████| 2570/2570 [00:59<00:00, 42.84it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,32):\n",
    "    q_file = f'../log/ema_0.9999_2700000/{i}.mid'\n",
    "    ks = songs.pianorolls\n",
    "    process_query(q_file,ks,sim_function=iou)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "q_id = path.basename(q_file).replace('.mid','')\n",
    "q_dir = path.dirname(q_file)\n",
    "save_dir = path.join(q_dir,'similar',q_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../log/ema_0.9999_2700000',\n",
       " '10',\n",
       " '../log/ema_0.9999_2700000/10.mid',\n",
       " '../log/ema_0.9999_2700000/similar/10')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "q_dir,q_id,q_file,save_dir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PianoRoll Bar 048 - 064 of Sia - Move Your Body (Alan Walker Remix) _ Piano Cover by Pianella Piano"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.slice(q_pos_on_k*32,q_pos_on_k*32+(q_end-q_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 253853/253853 [00:17<00:00, 14686.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] [0.26604390144348145, 0.2663997411727905, 0.2673889696598053, 0.2691650688648224, 0.2694220244884491, 0.271394819021225, 0.27623701095581055, 0.28327450156211853, 0.29047897458076477, 0.5194606781005859]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def sort_by_similarity(x,ys : 'list[PianoRoll]' ,sim_function = mse):\n",
    "    scores={} \n",
    "    x = x.to_tensor()/128\n",
    "    for y in tqdm(ys):\n",
    "        scores[y]=sim_function(x,y.to_tensor(0,x.shape[0],padding=True)/128).item()\n",
    "    ys = sorted(ys,key=lambda y: scores[y])\n",
    "    scores = sorted(scores.values())\n",
    "    return ys, scores, x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# query\n",
    "query_file = '../log/ema_0.9999_2700000/6.mid'\n",
    "query = PianoRoll.from_midi(query_file).slice(32*14,32*15)\n",
    "\n",
    "# save query\n",
    "p = query_file.replace('.mid','similar')+'/query.mid'\n",
    "os.makedirs(path.dirname(p),exist_ok=True)\n",
    "query.to_midi(p)\n",
    "\n",
    "keys.append(query) # add query to keys to check similarity function\n",
    "\n",
    "# sort by similarity\n",
    "ys, scores, x = sort_by_similarity(query,keys,iou)\n",
    "print(scores[:10],scores[-10:])\n",
    "\n",
    "# save 10 most similar\n",
    "for i, y in enumerate(list(reversed(ys))[:20]):\n",
    "    p = query_file.replace('.mid','similar')+f'/{i}.mid'\n",
    "    os.makedirs(path.dirname(p),exist_ok=True)\n",
    "    y.to_midi(p)\n",
    "\n",
    "\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__main__'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'050'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=50\n",
    "# format to 000\n",
    "f'{a:03d}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.5801)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sim_map(q_bar,q_bar,iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('music')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3eaf417fe2c1d8874a3e92f187d4f71d692dc094dc77bbe31ebc3687fc476eb8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
